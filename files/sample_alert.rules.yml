---
groups:
  - name: /vagrant/site-roles/shelleg.prometheus/files/sample_alert.rules
    rules:
      - alert: HighErrorRate
        expr: sum(rate(http_requests_total{status=~"5.."}[5m])) BY (job, path) / sum(rate(http_requests_total[5m]))
          BY (job, path) * 100 > 1
        for: 10m
        annotations:
          description: '{{$labels.job}} has {{$value}}% 5xx errors on {{$labels.path}}'
          summary: high number of 5xx errors
      - alert: DailyTest
        expr: vector(1) > 0
        for: 1m
        annotations:
          description: daily alert test
          summary: daily alert test
      - alert: service_down
        expr: up == 0
        labels:
          severity: major
          value: '{{$value}}'
      - alert: service_up
        expr: up == 1
        labels:
          severity: ok
          value: '{{$value}}'
      - alert: high_load
        expr: node_load1 > 0.5
        annotations:
          description: '{{ $labels.instance }} of job {{ $labels.job }} is under high
            load.'
          summary: Instance {{ $labels.instance }} under high load
      - alert: ApiRequestsHigh
        expr: alerta_alerts_total > 1
        labels:
          service: Alerta
          severity: major
          value: '{{$value}} req/s'
        annotations:
          description: API request rate of {{$value}} req/s is high (threshold 3 req/s)
          runbook: http://wiki/runbook
          summary: API request rate high
      - alert: Test
        expr: alerta_alerts_total > 0
        labels:
          service: Alerta
          severity: warning
          value: '{{$value}}'
        annotations:
          description: API request rate of {{$value}} req/s is high (threshold 3 req/s)
          runbook: http://
          summary: API request rate high
      - alert: CompleteAlert
        expr: alerta_alerts_total > 0
        labels:
          service: Web
          severity: minor
          value: '{{$value}}'
        annotations:
          description: complete alert triggered at {{$value}}
          summary: alert triggered
      - alert: high_cpu_usage_on_node
        expr: sum(rate(process_cpu_seconds_total[5m])) BY (instance) * 100 > 70
        for: 5m
        annotations:
          description: '{{ $labels.instance }} is using a LOT of CPU. CPU usage is {{
            humanize $value}}%.'
          summary: HIGH CPU USAGE WARNING ON '{{ $labels.instance }}'
      - alert: high_memory_usage_on_node
        expr: ((node_memory_MemTotal - node_memory_MemAvailable) / node_memory_MemTotal)
          * 100 > 80
        for: 5m
        annotations:
          description: '{{ $labels.instance }} is using a LOT of MEMORY. MEMORY usage
            is over {{ humanize $value}}%.'
          summary: HIGH MEMORY USAGE WARNING TASK ON '{{ $labels.host }}'
      - alert: high_la_usage_on_node
        expr: node_load5 > 5
        for: 5m
        annotations:
          description: '{{ $labels.instance }} has a high load average. Load Average 5m
            is {{ humanize $value}}.'
          summary: HIGH LOAD AVERAGE WARNING ON '{{ $labels.instance }}'
      - alert: monitoring_service_down
        expr: up == 0
        for: 5m
        annotations:
          description: The monitoring service '{{ $labels.job }}' is down.
          summary: 'MONITORING SERVICE DOWN WARNING: NODE ''{{ $labels.host }}'''
      - alert: node_running_out_of_disk_space
        expr: (node_filesystem_size{mountpoint="/"} - node_filesystem_free{mountpoint="/"})
          * 100 / node_filesystem_size{mountpoint="/"} > 80
        for: 5m
        annotations:
          description: More than 80% of disk used. Disk usage {{ humanize $value }}%.
          summary: 'LOW DISK SPACE WARING: NODE ''{{ $labels.host }}'''
      - alert: disk_will_fill_in_8_hours
        expr: predict_linear(node_filesystem_free{mountpoint="/"}[1h], 8 * 3600) < 0
        for: 5m
        annotations:
          description: '{{ $labels.instance }} is writing a lot.'
          summary: 'DISK SPACE FULL IN 8 HOURS: NODE ''{{ $labels.host }}'''
      - alert: high_cpu_usage_on_container
        expr: sum(rate(container_cpu_usage_seconds_total{container_label_com_docker_swarm_task_name=~".+"}[5m]))
          BY (container_label_com_docker_swarm_task_name, instance) * 100 > 200
        for: 5m
        annotations:
          description: '{{ $labels.container_label_com_docker_swarm_task_name }} is using
            a LOT of CPU. CPU usage is {{ humanize $value}}%.'
          summary: 'HIGH CPU USAGE WARNING: TASK ''{{ $labels.container_label_com_docker_swarm_task_name
            }}'' on ''{{ $labels.instance }}'''
      - alert: container_eating_memory
        expr: sum(container_memory_rss{container_label_com_docker_swarm_task_name=~".+"})
          BY (instance, name) > 2.5e+09
        for: 5m
        annotations:
          description: '{{ $labels.container_label_com_docker_swarm_task_name }} is eating
            up a LOT of memory. Memory consumption of {{ $labels.container_label_com_docker_swarm_task_name
            }} is at {{ humanize $value}}.'
          summary: 'HIGH MEMORY USAGE WARNING: TASK ''{{ $labels.container_label_com_docker_swarm_task_name
            }}'' on ''{{ $labels.instance }}'''
      - alert: site_down
        expr: probe_success == 0
        for: 5m
        annotations:
          description: '{{$labels.instance}} has been down for more than 10 minutes.'
          summary: '{{$labels.instance}} down'
      - alert: container_missing_in_piwik_stack
        expr: count(container_last_seen{container_label_com_docker_stack_namespace="piwik"})
          < 3
        for: 5m
        annotations:
          description: There are less than three container in the Piwik stack
          summary: A container is missing in Piwik stack
      - alert: container_not_in_running_state
        expr: sum(container_tasks_state{state!="running"}) BY (container_label_com_docker_stack_namespace)
          > 0
        for: 1m
        annotations:
          description: '{{ $labels.container_label_com_docker_swarm_task_name }} has a
            container not in running state on {{ $labels.instance }}'
          summary: Container not in running state in stack '{{ $labels.container_label_com_docker_swarm_task_name
            }}' on '{{ $labels.instance }}'
...
